{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader,PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shrey\\Desktop\\Work\\AI Toolkit\\Code\\RAG\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\shrey\\Desktop\\Work\\AI Toolkit\\Code\\RAG\\.venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "#Directory of the PDF Files\n",
    "dir = 'docs/'\n",
    "\n",
    "# OS Embedding model from Huggingface\n",
    "embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(dir):\n",
    "    loader=DirectoryLoader(dir,loader_cls=PyMuPDFLoader,use_multithreading=True,max_concurrency=128,show_progress=True,silent_errors=True)\n",
    "    documents=loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the documents into chunks\n",
    "def split_docs(documents,chunk_size=1000,chunk_overlap=100):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap)\n",
    "    docs=text_splitter.split_documents(documents)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents=load_docs(dir)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "doc=split_docs(documents)\n",
    "print(len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to=Chroma.from_documents(documents=doc,embedding=embeddings,persist_directory='./ai-toolkit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"What is Fine tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'author': '', 'creationDate': \"D:20240708144232+00'00'\", 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36', 'file_path': 'docs\\\\Finetune.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': \"D:20240708144232+00'00'\", 'page': 1, 'producer': 'Skia/PDF m126', 'source': 'docs\\\\Finetune.pdf', 'subject': '', 'title': 'Fine-tune a model with the AI Toolkit for Visual Studio Code | Microsoft Learn', 'total_pages': 8, 'trapped': ''}, page_content='AI Toolkit: Validate Environment prerequisites.\\nIf your local device passes the validation checks, the Setup WSL Environment button\\nwill be enabled for you to select. This will install all the dependencies required to run\\nfine-tuning jobs.\\nIf your local computer does not have an Nvidia GPU device, it is possible to fine-tune on\\na cloud VM - both Windows and Linux - with an Nvidia GPU (if you have quota). In\\nAzure, you can fine-tune with the following VM series:\\nNCasT4_v3-series\\nNC A100 v4-series\\nND A100 v4-series\\nNCads H100 v5-series\\nNCv3-series\\nNVadsA10 v5-series\\nThe AI Toolkit uses a method called QLoRA, which combines quantization and low-rank\\nadaptation (LoRA) to fine-tune models with your own data. Learn more about QLoRA at\\nQLoRA: Efficient Finetuning of Quantized LLMs\\n.\\nTo start a new fine-tuning session using QLoRA, select the Model Fine-tuning item in AI\\nToolkit.\\nStart by entering a unique Project Name and a Project Location. A new folder with the'), Document(metadata={'author': '', 'creationDate': \"D:20240708144232+00'00'\", 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36', 'file_path': 'docs\\\\Finetune.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': \"D:20240708144232+00'00'\", 'page': 5, 'producer': 'Skia/PDF m126', 'source': 'docs\\\\Finetune.pdf', 'subject': '', 'title': 'Fine-tune a model with the AI Toolkit for Visual Studio Code | Microsoft Learn', 'total_pages': 8, 'trapped': ''}, page_content='ﾉ\\nExpand table\\nStep 3: Execute fine-tuning job\\n7/8/24, 8:12 PM\\nFine-tune a model with the AI Toolkit for Visual Studio Code | Microsoft Learn\\nhttps://learn.microsoft.com/en-us/windows/ai/toolkit/toolkit-fine-tune\\n6/8'), Document(metadata={'author': '', 'creationDate': \"D:20240708144232+00'00'\", 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36', 'file_path': 'docs\\\\Finetune.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': \"D:20240708144232+00'00'\", 'page': 2, 'producer': 'Skia/PDF m126', 'source': 'docs\\\\Finetune.pdf', 'subject': '', 'title': 'Fine-tune a model with the AI Toolkit for Visual Studio Code | Microsoft Learn', 'total_pages': 8, 'trapped': ''}, page_content=\"You'll then be prompted to configure your fine-tuning project settings. Ensure the Fine-\\ntune locally checkbox is ticked (in the future the VS Code extension will allow you to\\noffload fine-tuning to the cloud):\\nThere are two settings available in the Model inference section:\\nModel inference settings\\n7/8/24, 8:12 PM\\nFine-tune a model with the AI Toolkit for Visual Studio Code | Microsoft Learn\\nhttps://learn.microsoft.com/en-us/windows/ai/toolkit/toolkit-fine-tune\\n3/8\"), Document(metadata={'author': '', 'creationDate': \"D:20240708144232+00'00'\", 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36', 'file_path': 'docs\\\\Finetune.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': \"D:20240708144232+00'00'\", 'page': 3, 'producer': 'Skia/PDF m126', 'source': 'docs\\\\Finetune.pdf', 'subject': '', 'title': 'Fine-tune a model with the AI Toolkit for Visual Studio Code | Microsoft Learn', 'total_pages': 8, 'trapped': ''}, page_content='Source max\\nlength\\nThe maximum number of tokens per training sample.\\nPad to max\\nlength\\nAdd a PAD token to the training sample until the max number of tokens.\\nThe following settings are available in the Fine tune section to further configure the\\nfine-tuning process:\\nﾉ\\nExpand table\\nData settings\\nﾉ\\nExpand table\\nFine-tune settings\\nﾉ\\nExpand table\\n7/8/24, 8:12 PM\\nFine-tune a model with the AI Toolkit for Visual Studio Code | Microsoft Learn\\nhttps://learn.microsoft.com/en-us/windows/ai/toolkit/toolkit-fine-tune\\n4/8')]\n",
      "AI Toolkit: Validate Environment prerequisites.\n",
      "If your local device passes the validation checks, the Setup WSL Environment button\n",
      "will be enabled for you to select. This will install all the dependencies required to run\n",
      "fine-tuning jobs.\n",
      "If your local computer does not have an Nvidia GPU device, it is possible to fine-tune on\n",
      "a cloud VM - both Windows and Linux - with an Nvidia GPU (if you have quota). In\n",
      "Azure, you can fine-tune with the following VM series:\n",
      "NCasT4_v3-series\n",
      "NC A100 v4-series\n",
      "ND A100 v4-series\n",
      "NCads H100 v5-series\n",
      "NCv3-series\n",
      "NVadsA10 v5-series\n",
      "The AI Toolkit uses a method called QLoRA, which combines quantization and low-rank\n",
      "adaptation (LoRA) to fine-tune models with your own data. Learn more about QLoRA at\n",
      "QLoRA: Efficient Finetuning of Quantized LLMs\n",
      ".\n",
      "To start a new fine-tuning session using QLoRA, select the Model Fine-tuning item in AI\n",
      "Toolkit.\n",
      "Start by entering a unique Project Name and a Project Location. A new folder with the\n"
     ]
    }
   ],
   "source": [
    "db1=Chroma(persist_directory='./ai-toolkit',embedding_function=embeddings)\n",
    "results=db1.similarity_search(query)\n",
    "print(results)\n",
    "print(results[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
